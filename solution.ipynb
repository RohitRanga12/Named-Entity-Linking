{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c21d301",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy==3.0.6\n",
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178578ac",
   "metadata": {},
   "source": [
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "defe15e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.kb import InMemoryLookupKB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b61f4b",
   "metadata": {},
   "source": [
    "#### Read the 3 json files into dataframes (just for visualizing samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03795bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_articles_new_df = pd.read_json(\"news_articles-new.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37a02a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_articles_gold_df = pd.read_json(\"news_articles-gold.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b825b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_df = pd.read_json(\"company_collection.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16ef2ae",
   "metadata": {},
   "source": [
    "#### Assign unique ID to each company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "629b00fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_df['QID'] = companies_df.index\n",
    "companies_df['QID'] = companies_df['QID'].apply(lambda elem: str(elem))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6434066",
   "metadata": {},
   "source": [
    "#### View the companies info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "495c2586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>founded</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>headquarters</th>\n",
       "      <th>industry_label</th>\n",
       "      <th>QID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100 Thieves</td>\n",
       "      <td>2016</td>\n",
       "      <td>100 Thieves, LLC, an esports organization, com...</td>\n",
       "      <td>100thieves.com</td>\n",
       "      <td>United States</td>\n",
       "      <td>Retail &amp; commerce | Sports &amp; gaming</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ten eleven ventures</td>\n",
       "      <td>2014</td>\n",
       "      <td></td>\n",
       "      <td>1011vc.com</td>\n",
       "      <td></td>\n",
       "      <td>Banking &amp; finance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name founded  \\\n",
       "0          100 Thieves    2016   \n",
       "1  ten eleven ventures    2014   \n",
       "\n",
       "                                         description             url  \\\n",
       "0  100 Thieves, LLC, an esports organization, com...  100thieves.com   \n",
       "1                                                         1011vc.com   \n",
       "\n",
       "    headquarters                       industry_label QID  \n",
       "0  United States  Retail & commerce | Sports & gaming   0  \n",
       "1                                   Banking & finance   1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcac90a4",
   "metadata": {},
   "source": [
    "#### View the \"news_articles-gold\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8084f863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>annotations</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Report: Adam Neumann, Benchmark Unloaded $676....</td>\n",
       "      <td>Report: Adam Neumann, Benchmark Unloaded $676....</td>\n",
       "      <td>{'WeWork': 'wework.com', 'Benchmark': 'benchma...</td>\n",
       "      <td>https://news.crunchbase.com/news/report-adam-n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Report: Palantir Could Go Public In The Next Year</td>\n",
       "      <td>Report: Palantir Could Go Public In The Next Y...</td>\n",
       "      <td>{'Palantir Technologies': 'palantir.com', 'Pal...</td>\n",
       "      <td>https://news.crunchbase.com/news/report-palant...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Report: Adam Neumann, Benchmark Unloaded $676....   \n",
       "1  Report: Palantir Could Go Public In The Next Year   \n",
       "\n",
       "                                                text  \\\n",
       "0  Report: Adam Neumann, Benchmark Unloaded $676....   \n",
       "1  Report: Palantir Could Go Public In The Next Y...   \n",
       "\n",
       "                                         annotations  \\\n",
       "0  {'WeWork': 'wework.com', 'Benchmark': 'benchma...   \n",
       "1  {'Palantir Technologies': 'palantir.com', 'Pal...   \n",
       "\n",
       "                                              source  \n",
       "0  https://news.crunchbase.com/news/report-adam-n...  \n",
       "1  https://news.crunchbase.com/news/report-palant...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_articles_gold_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a41dfbe",
   "metadata": {},
   "source": [
    "#### View the \"news_articles-new\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b9cd950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pinterest May Go Public In Q2 After Growing Ar...</td>\n",
       "      <td>Pinterest May Go Public In Q2 After Growing Ar...</td>\n",
       "      <td>https://news.crunchbase.com/news/pinterest-may...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arlo Opens At $18.50 After Pricing At $16</td>\n",
       "      <td>Arlo Opens At $18.50 After Pricing At $16. Mor...</td>\n",
       "      <td>https://news.crunchbase.com/news/arlo-opens-at...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Pinterest May Go Public In Q2 After Growing Ar...   \n",
       "1          Arlo Opens At $18.50 After Pricing At $16   \n",
       "\n",
       "                                                text  \\\n",
       "0  Pinterest May Go Public In Q2 After Growing Ar...   \n",
       "1  Arlo Opens At $18.50 After Pricing At $16. Mor...   \n",
       "\n",
       "                                              source  \n",
       "0  https://news.crunchbase.com/news/pinterest-may...  \n",
       "1  https://news.crunchbase.com/news/arlo-opens-at...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_articles_new_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d580adc5",
   "metadata": {},
   "source": [
    "#### Number of companies in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66d03e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3330"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(companies_df['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28d114e",
   "metadata": {},
   "source": [
    "#### Number of unique companies based on name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fe30007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3293"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(companies_df['name'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2899e6e",
   "metadata": {},
   "source": [
    "#### Number of companies with no description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84de7fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([desc for desc in companies_df['description'] if desc.strip() == ''])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fac3e19",
   "metadata": {},
   "source": [
    "#### Number of articles with annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cc0e562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news_articles_gold_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9ffaa1",
   "metadata": {},
   "source": [
    "#### Number of articles without annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a0b1faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news_articles_new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aa5bd7",
   "metadata": {},
   "source": [
    "#### Load the spacy model which will be used as base model for entity linker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48879b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a72f73",
   "metadata": {},
   "source": [
    "#### Create dictionary of names, descriptions and urls for the entities (companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e704088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qid_to_names = {}\n",
    "qid_to_descriptions = {}\n",
    "qid_to_urls = {}\n",
    "\n",
    "for index, row in companies_df.iterrows():\n",
    "    qid_to_names[row['QID']] = row['name']\n",
    "    qid_to_descriptions[row['QID']] = row['description']\n",
    "    qid_to_urls[row['QID']] = row['url']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95d88e3",
   "metadata": {},
   "source": [
    "#### Create the knowledge base and save it to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0be56836",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb = InMemoryLookupKB(vocab=nlp.vocab, entity_vector_length=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44717585",
   "metadata": {},
   "outputs": [],
   "source": [
    "for qid, desc in qid_to_descriptions.items():\n",
    "    desc_doc = nlp(desc)\n",
    "    desc_encoding = desc_doc.vector\n",
    "    kb.add_entity(entity=qid, entity_vector=desc_encoding, freq=342)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49ee9c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Azimo' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Bird' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Blink' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Bright Health' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Canary' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Catalyst' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Chiquita Brands International' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Confluent' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'CST Brands' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Data Collective' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Endeavor' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Drafted' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Fountain' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Google' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Grab' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Homebrew' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Curaleaf' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Knock' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'LAUNCH' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Loft' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Medco Health Solutions' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Meritech' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Microsoft' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Mirror' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Peloton' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Palantir' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Portal' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Saudi Aramco' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Slow Ventures' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Snapchat' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Heap' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Affinity' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Twitch' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Uplevel' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Vroom' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n",
      "/var/folders/tj/f5_6cgfn1c10b4qbr2h2fbg00000gn/T/ipykernel_23538/223248971.py:2: UserWarning: [W017] Alias 'Wave' already exists in the Knowledge Base.\n",
      "  kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])\n"
     ]
    }
   ],
   "source": [
    "for qid, name in qid_to_names.items():\n",
    "    kb.add_alias(alias=name, entities=[str(qid)], probabilities=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc70a135",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb.to_disk(\"my_kb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3049d1d",
   "metadata": {},
   "source": [
    "#### Prepare the dataset in the appropriate format for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f03b32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_info_from_text(text:str, entity:str):\n",
    "    \"\"\"\n",
    "    Given a text and a named entity, this function returns the entity info (start index, end index, ent label)\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    entity_info = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.text == entity:\n",
    "            entity_info.append((ent.start_char, ent.end_char, 'ORG'))\n",
    "    return entity_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68873384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_id_from_url(url:str, company_name):\n",
    "    qids = list(qid_to_urls.keys())\n",
    "    urls = list(qid_to_urls.values())\n",
    "    \n",
    "    try:\n",
    "        # url is found in qid_to_urls dict, hence return the qid\n",
    "        index = urls.index(url) \n",
    "        return qids[index]\n",
    "    except ValueError as e:\n",
    "        \"\"\"\n",
    "            url is not found in qid_to_urls, hence add the url to the qid_to_urls \n",
    "            and also update qid_to_names and qid_to_descriptions dictionaries. Return the new qid      \n",
    "        \"\"\"\n",
    "        print(url + \" not found in existing qid_to_urls dictionary\")\n",
    "        new_id = str(len(qid_to_urls)+1)\n",
    "        qid_to_urls[new_id] = url\n",
    "        qid_to_names[new_id] = company_name\n",
    "        qid_to_descriptions = \"\"\n",
    "        return new_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a4ed2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset():\n",
    "    dataset = []\n",
    "    \n",
    "    for index, row in news_articles_gold_df.iterrows():\n",
    "        annotations = row['annotations']\n",
    "        text = row['text']\n",
    "        links = {}\n",
    "        entities = []\n",
    "        \n",
    "        for company_name, url in annotations.items():\n",
    "            entity_id = get_company_id_from_url(url, company_name)\n",
    "            \n",
    "            entity_info = get_entity_info_from_text(text, company_name)\n",
    "            for (start_index, end_index, ent_label) in entity_info:\n",
    "                links[(start_index, end_index)] = {entity_id: 1.0}\n",
    "                entities.append((start_index, end_index, ent_label))\n",
    "                \n",
    "        data = (\n",
    "            text,\n",
    "            {\n",
    "                \"links\": links,\n",
    "                \"entities\": entities\n",
    "            },\n",
    "            \n",
    "        )\n",
    "\n",
    "        dataset.append(data)\n",
    "            \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfa560c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparxsif.com/en not found in existing qid_to_urls dictionary\n",
      "incubatefund.com/en/aboutus not found in existing qid_to_urls dictionary\n",
      "tte-net.com/english/index.html not found in existing qid_to_urls dictionary\n",
      "companionfund.com not found in existing qid_to_urls dictionary\n",
      "leftlanecap.com not found in existing qid_to_urls dictionary\n",
      "darktrace.com/en not found in existing qid_to_urls dictionary\n",
      "blackberry.com/us/en/cylance not found in existing qid_to_urls dictionary\n",
      "breakthroughenergy.org not found in existing qid_to_urls dictionary\n",
      "granthamtrust.org not found in existing qid_to_urls dictionary\n",
      "blingcap.com not found in existing qid_to_urls dictionary\n",
      "fireboltventures.com not found in existing qid_to_urls dictionary\n",
      "capital-en.tcl.com not found in existing qid_to_urls dictionary\n",
      "flourishventures.com not found in existing qid_to_urls dictionary\n",
      "myhippo.com not found in existing qid_to_urls dictionary\n",
      "eu.lululemon.com not found in existing qid_to_urls dictionary\n",
      "uber.com/de/en not found in existing qid_to_urls dictionary\n",
      "news.crunchbase.com not found in existing qid_to_urls dictionary\n",
      "uber.com/de/en/freight not found in existing qid_to_urls dictionary\n",
      "sanofiventures.com not found in existing qid_to_urls dictionary\n",
      "ignitexl.vc not found in existing qid_to_urls dictionary\n",
      "centaurusenergy.com not found in existing qid_to_urls dictionary\n",
      "pandemictech.com not found in existing qid_to_urls dictionary\n",
      "lunpartners.com not found in existing qid_to_urls dictionary\n",
      "softbank.jp/en not found in existing qid_to_urls dictionary\n",
      "fidocure.com not found in existing qid_to_urls dictionary\n",
      "temasek.com.sg/en/index not found in existing qid_to_urls dictionary\n",
      "prestonwernerventures.com not found in existing qid_to_urls dictionary\n",
      "worldhousing.org not found in existing qid_to_urls dictionary\n"
     ]
    }
   ],
   "source": [
    "dataset = prepare_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac37b4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Accolade Is Latest To Join Health Service IPO Bandwagon. To launch a successful IPO in the current market environment, it seems to help to be a fast-growing health care services provider. Shares of One Medical , a provider of primary care clinics and telemedicine, closed up nearly 60 percent in first-day trading a month ago. Since then, it’s largely held on to those gains. Subscribe to the Crunchbase Daily Progyny , a benefits management focusing on fertility, meanwhile, has seen its shares roughly double from its initial offer price back in October. While the broader markets have swooned, Progyny has held strong. Now, another well-funded health service company is betting investor enthusiasm for the space will trump market skittishness. Accolade , a service provider that serves as a kind of go-between for consumers, employers and health insurance companies, is seeking to raise up to $100 million in an IPO, according to a prospectus filed late Friday. Like most venture-backed companies on the IPO path, Accolade is posting both strong growth and persistent losses. Its most recent financials are for the ninth-month period ending Nov. 30, for which it reported revenue of $88 million, and a net loss of $49 million. For the corresponding period a year earlier, revenue was $60 million, with the same net loss of $49 million. (Accolade operates on a fiscal year ending in February, so results for its last full fiscal year are not yet available.) The company’s pitch to investors is that its platform will see continued large-scale adoption as health care plans and services become increasingly complicated for people to navigate. Its customers are primarily employers that deploy Accolade to provide employees and their families “a single place to turn for their health, healthcare, and benefits needs,” per the IPO prospectus. Accolades core offerings includes a software platform backed by a support staff of health assistants and clinicians. Headquartered in Seattle, with significant operations in the Philadelphia area, Accolade has raised $237 million in known funding since its founding in 2007. Key backers include Andreessen Horowitz , Comcast Ventures and Carrick Capital Partners . Illustration: Li-Anne Dias .',\n",
       " {'links': {(2159, 2175): {'685': 1.0},\n",
       "   (1694, 1702): {'49': 1.0},\n",
       "   (2039, 2047): {'49': 1.0},\n",
       "   (597, 604): {'2362': 1.0},\n",
       "   (2180, 2204): {'561': 1.0}},\n",
       "  'entities': [(2159, 2175, 'ORG'),\n",
       "   (1694, 1702, 'ORG'),\n",
       "   (2039, 2047, 'ORG'),\n",
       "   (597, 604, 'ORG'),\n",
       "   (2180, 2204, 'ORG')]})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[34]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d4d5c5",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "- some urls in gold data not found in companies list\n",
    "\n",
    "- different companies with same url found in gold data\n",
    "\n",
    "- same company name, but different URLs in companies file, e.g. Endeavor and a few others\n",
    "\n",
    "- same company name, but different URLs in annotated file, e.g. \"uber.com\" and \"uber.com/de/en\" for company Uber\n",
    "    - this was a challenge because, as part of my algorithm, to create the training data, I obtain the entity ID by matching the URL in companies list with the URL given in annotated data\n",
    "     \n",
    "    I am using URL and not name, because I found all URLs in the companies list to be unique, but found duplicates in company name\n",
    "\n",
    "- \"description\" field has junk info e.g. \"cloud-data_crunchbase_2011 worthy Appin tweetprocesor stanford group.pdf.\"\n",
    "\n",
    "- for 165 companies, \"description\" field is empty. We need to collect those descriptions\n",
    "\n",
    "- many cases where \"name\" field has URL, e.g. \"name\": \"Andreessen Horowitz a16z.com\"\n",
    "\n",
    "- \"name\" field has special chars, e.g.   \"name\": \"Alb\\u00e9a Group\"\n",
    "\n",
    "#### Improvements that I would have done if I had more time \n",
    "\n",
    "- clean up the companies file \n",
    "    - add descriptions for companies wherever description was empty (if allowed, we can use services like CoreSignal API)\n",
    "    - remove urls from company names \n",
    "            use this regex to detect such cases in the name field\n",
    "            .+ (.*\\.(com|io|vc))\n",
    "    - clean descriptions wherever junk info was there\n",
    "- gather aliases/synonyms for company names (if allowed, we can use services like Seravia API)\n",
    "    - add to knowledge base\n",
    "    - this could improve model performance\n",
    "- gather more annotated data for training \n",
    "- try using some transformer model as base model within spacy instead of en_core_web_lg\n",
    "- perform more detailed hyperparameter tuning when training the EL model\n",
    "- stratify the train and test dataset based on entity_id, so that the model can learn uniformly well across entity IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dd073b",
   "metadata": {},
   "source": [
    "#### Shuffle the train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24bc3d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "train_dataset = dataset[0:30]\n",
    "test_dataset = dataset[30:40]\n",
    "\n",
    "random.shuffle(train_dataset)\n",
    "random.shuffle(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257013",
   "metadata": {},
   "source": [
    "#### Train the EL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "949e1a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.training import Example\n",
    "\n",
    "TRAIN_EXAMPLES = []\n",
    "\n",
    "if \"sentencizer\" not in nlp.pipe_names:\n",
    "    nlp.add_pipe(\"sentencizer\")\n",
    "    \n",
    "sentencizer = nlp.get_pipe(\"sentencizer\")\n",
    "count=0\n",
    "for text, annotation in train_dataset:\n",
    "    example = Example.from_dict(nlp.make_doc(text), annotation)\n",
    "    example.reference = sentencizer(example.reference)\n",
    "    TRAIN_EXAMPLES.append(example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4dd7f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.ml.models import load_kb\n",
    "\n",
    "entity_linker = nlp.add_pipe(\"entity_linker\", config={\"incl_prior\": False}, last=True)\n",
    "entity_linker.initialize(get_examples=lambda: TRAIN_EXAMPLES, kb_loader=load_kb(\"my_kb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "affaf2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Losses {'entity_linker': 5.923153295781878}\n",
      "50 Losses {'entity_linker': 1.2630623374866623}\n",
      "100 Losses {'entity_linker': 1.1509348904093106}\n",
      "150 Losses {'entity_linker': 1.1877119670197427}\n",
      "200 Losses {'entity_linker': 0.8379911234824664}\n",
      "250 Losses {'entity_linker': 1.598684724757814}\n",
      "300 Losses {'entity_linker': 1.6752873020491215}\n",
      "350 Losses {'entity_linker': 0.8064408239391114}\n",
      "400 Losses {'entity_linker': 0.8123272939026356}\n",
      "450 Losses {'entity_linker': 1.3152976576285353}\n",
      "499 Losses {'entity_linker': 1.3444068133831024}\n"
     ]
    }
   ],
   "source": [
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "with nlp.select_pipes(enable=[\"entity_linker\"]):   # train only the entity_linker\n",
    "    optimizer = nlp.resume_training()\n",
    "    for itn in range(500):   # 500 iterations \n",
    "        random.shuffle(TRAIN_EXAMPLES)\n",
    "        batches = minibatch(TRAIN_EXAMPLES, size=compounding(4.0, 32.0, 1.001))  # increasing batch sizes\n",
    "        losses = {}\n",
    "        for batch in batches:\n",
    "            nlp.update(\n",
    "                batch,   \n",
    "                drop=0.2,      # to prevent overfitting\n",
    "                losses=losses,\n",
    "                sgd=optimizer,\n",
    "            )\n",
    "        if itn % 50 == 0:\n",
    "            print(itn, \"Losses\", losses)   # print the training loss\n",
    "print(itn, \"Losses\", losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2055132",
   "metadata": {},
   "source": [
    "#### Test the model on the test dataset, which was unseen during training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b99d7e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [text for text, true_annot in test_dataset]\n",
    "true_annotations = [true_annot['links'] for text, true_annot in test_dataset]\n",
    "docs = nlp.pipe(texts)\n",
    "\n",
    "# gathering the model predictions (entity IDs) in the right format for evaluation \n",
    "overall_model_predictions = []\n",
    "for doc in docs:\n",
    "    model_predictions = set()\n",
    "    for ent in doc.ents:\n",
    "        if ent.kb_id_ != 'NIL':\n",
    "            model_predictions.add(ent.kb_id_)\n",
    "    overall_model_predictions.append(model_predictions)\n",
    "    \n",
    "# gathering the gold entities in the right format for evaluation \n",
    "overall_gold_entity_ids = []\n",
    "for true_annot in true_annotations:\n",
    "    gold_entity_ids = set()\n",
    "    for key, value in true_annot.items():\n",
    "        for entity_id, _ in value.items():\n",
    "            gold_entity_ids.add(entity_id)\n",
    "    overall_gold_entity_ids.append(gold_entity_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6713c61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'1761', '2448', '2488'},\n",
       " {'1023'},\n",
       " {'1021', '1224', '1660', '2042'},\n",
       " {'1068', '2771', '3036'},\n",
       " {'2077', '2336', '766'},\n",
       " {'1726', '2312', '2458', '783'},\n",
       " {'2362', '49', '561', '685'},\n",
       " {'1191', '1217', '2722', '380'},\n",
       " {'186', '2892', '907'},\n",
       " {'2636', '2873', '3218', '566'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_model_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10826d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'1761', '2448', '2488', '3358'},\n",
       " {'1023', '27', '3355'},\n",
       " {'1021', '1224', '1660', '2042', '27', '3357'},\n",
       " {'1068', '2080', '2771', '3036'},\n",
       " {'1504', '2077', '2336', '765'},\n",
       " {'1726', '2312', '2458', '783'},\n",
       " {'2362', '49', '561', '685'},\n",
       " {'1191', '1217', '3354', '380'},\n",
       " {'1504', '186', '3356', '907'},\n",
       " {'1132', '2636', '3218', '3353', '566'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_gold_entity_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651e700c",
   "metadata": {},
   "source": [
    "#### Evaluate the model which we have trained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "baae7b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision (on unseen test data): 88.33\n",
      "Average recall (on unseen test data): 68.5\n"
     ]
    }
   ],
   "source": [
    "avg_precision = 0.0\n",
    "avg_recall = 0.0\n",
    "\n",
    "for model_prediction, gold_entities in zip(overall_model_predictions, overall_gold_entity_ids):\n",
    "    intersection = model_prediction.intersection(gold_entities)\n",
    "    precision = float(len(intersection)/len(model_prediction)) * 100\n",
    "    recall = float(len(intersection)/len(gold_entities)) * 100\n",
    "    avg_precision = avg_precision + precision\n",
    "    avg_recall = avg_recall + recall\n",
    "\n",
    "avg_recall = avg_recall/len(overall_model_predictions)\n",
    "avg_precision = avg_precision/len(overall_model_predictions)\n",
    "\n",
    "print(\"Average precision (on unseen test data): \" + str(round(avg_precision,2)))\n",
    "print(\"Average recall (on unseen test data): \" + str(round(avg_recall,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe4816e",
   "metadata": {},
   "source": [
    "#### Run predictions on \"news_articles-new\" and save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d4aae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = news_articles_new_df['text'].tolist()\n",
    "docs = nlp.pipe(texts)\n",
    "annotations = []\n",
    "\n",
    "for doc in docs:\n",
    "    annotation = {}\n",
    "    for ent in doc.ents:\n",
    "        if ent.kb_id_ != 'NIL': # entities which have been linked to KB\n",
    "            url = qid_to_urls[ent.kb_id_]\n",
    "            annotation[ent.text] = url\n",
    "        else: \n",
    "            if ent.label_ == 'ORG': # entities which have been identified as ORG by the model, but not found in KB\n",
    "                annotation[ent.text] = ''\n",
    "    annotations.append(annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ada064d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_articles_new_df['annotation'] = annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "383d73e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pinterest May Go Public In Q2 After Growing Ar...</td>\n",
       "      <td>Pinterest May Go Public In Q2 After Growing Ar...</td>\n",
       "      <td>https://news.crunchbase.com/news/pinterest-may...</td>\n",
       "      <td>{'Morning Markets': '', 'the Wall Street Journ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arlo Opens At $18.50 After Pricing At $16</td>\n",
       "      <td>Arlo Opens At $18.50 After Pricing At $16. Mor...</td>\n",
       "      <td>https://news.crunchbase.com/news/arlo-opens-at...</td>\n",
       "      <td>{'IPO': '', 'Sonos': 'sonos.com', 'Arlo Techno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SoftBank, Kakao Give Radish $63M Series A Boos...</td>\n",
       "      <td>SoftBank, Kakao Give Radish $63M Series A Boos...</td>\n",
       "      <td>https://news.crunchbase.com/news/softbank-kaka...</td>\n",
       "      <td>{'SoftBank': 'softbank.jp', 'Kakao Give': '', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Open Source Software Is Big Business With Big ...</td>\n",
       "      <td>Open Source Software Is Big Business With Big ...</td>\n",
       "      <td>https://news.crunchbase.com/news/open-source-s...</td>\n",
       "      <td>{'OSS': '', 'Microsoft': 'azure.microsoft.com/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deflated, Uber May Swap Anniversary Balloons F...</td>\n",
       "      <td>Deflated, Uber May Swap Anniversary Balloons F...</td>\n",
       "      <td>https://news.crunchbase.com/news/deflated-uber...</td>\n",
       "      <td>{'Deflated': '', 'Uber': 'uber.com', 'the Crun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Pinterest May Go Public In Q2 After Growing Ar...   \n",
       "1          Arlo Opens At $18.50 After Pricing At $16   \n",
       "2  SoftBank, Kakao Give Radish $63M Series A Boos...   \n",
       "3  Open Source Software Is Big Business With Big ...   \n",
       "4  Deflated, Uber May Swap Anniversary Balloons F...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Pinterest May Go Public In Q2 After Growing Ar...   \n",
       "1  Arlo Opens At $18.50 After Pricing At $16. Mor...   \n",
       "2  SoftBank, Kakao Give Radish $63M Series A Boos...   \n",
       "3  Open Source Software Is Big Business With Big ...   \n",
       "4  Deflated, Uber May Swap Anniversary Balloons F...   \n",
       "\n",
       "                                              source  \\\n",
       "0  https://news.crunchbase.com/news/pinterest-may...   \n",
       "1  https://news.crunchbase.com/news/arlo-opens-at...   \n",
       "2  https://news.crunchbase.com/news/softbank-kaka...   \n",
       "3  https://news.crunchbase.com/news/open-source-s...   \n",
       "4  https://news.crunchbase.com/news/deflated-uber...   \n",
       "\n",
       "                                          annotation  \n",
       "0  {'Morning Markets': '', 'the Wall Street Journ...  \n",
       "1  {'IPO': '', 'Sonos': 'sonos.com', 'Arlo Techno...  \n",
       "2  {'SoftBank': 'softbank.jp', 'Kakao Give': '', ...  \n",
       "3  {'OSS': '', 'Microsoft': 'azure.microsoft.com/...  \n",
       "4  {'Deflated': '', 'Uber': 'uber.com', 'the Crun...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_articles_new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e94ea06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_articles_new_df.to_json(\"news_articles-linked.jsonl\", orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635d3d15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
